{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Lazy modules\") # Ignore lazy module warnings\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme() # Apply seaborn theme to plots\n",
    "\n",
    "from hyperopt import hp, tpe, rand\n",
    "\n",
    "from src.cross_validation import kfold_train\n",
    "from src.data import load_dataset, get_dataloader\n",
    "from src.evaluation import find_best_run, evaluate_checkpoint, find_best_hyperparameters\n",
    "from src.hyperopt import optimize_hyperparameters\n",
    "from src.logging import Logger\n",
    "from src.model import WFDefectDetector\n",
    "from src.training import train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(filepath=\"data/train\", resolution=(64, 64))\n",
    "test_dataset = load_dataset(filepath=\"data/test\", resolution=(64, 64))\n",
    "test_dataloader = get_dataloader(test_dataset, batch_size=8)\n",
    "\n",
    "space = {\n",
    "    \"kernel_size_conv\": hp.choice(\"kernel_size_conv\", [3, 5, 7]),\n",
    "    \"kernel_size_pool\": hp.choice(\"kernel_size_pool\", [2, 3]),\n",
    "    \"num_base_channels\": hp.choice(\"num_base_channels\", [4, 8, 16, 32]),\n",
    "    \"num_conv_blocks\": hp.choice(\"num_conv_blocks\", [2, 3]),\n",
    "    \"activation\": hp.choice(\"activation\", [\"tanh\", \"relu\", \"leakyrelu\"]),\n",
    "    \"optimizer\": hp.choice(\"optimizer\", [\"sgd\", \"rmsprop\", \"adam\"]),\n",
    "    \"learning_rate\": hp.uniform(\"learning_rate\", 0.0001, 0.01),\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = pathlib.Path(\"runs_manual\")\n",
    "trial_id = \"trial_before_hyperopt\"\n",
    "\n",
    "average_valid_loss = kfold_train(\n",
    "    dataset=train_dataset,\n",
    "    n_splits=5,\n",
    "    batch_size=8,\n",
    "    random_state=42,\n",
    "    num_conv_blocks=2,\n",
    "    num_base_channels=4,\n",
    "    kernel_size_conv=3,\n",
    "    kernel_size_pool=3,\n",
    "    activation=\"relu\",\n",
    "    optimizer=\"adam\",\n",
    "    learning_rate=0.001,\n",
    "    max_epochs=30,\n",
    "    patience=3,\n",
    "    device=device,\n",
    "    log_folder=log_folder,\n",
    "    trial_id=trial_id,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_left, ax_right) = plt.subplots(1, 2, dpi=250, figsize=(14, 6))\n",
    "ax_left.set_xlabel(\"Epoch\")\n",
    "ax_right.set_xlabel(\"Epoch\")\n",
    "ax_left.set_title(\"Training/validation loss\")\n",
    "ax_right.set_title(\"Training/validation accuracy\")\n",
    "\n",
    "best_run_dir = find_best_run(log_folder / trial_id)\n",
    "\n",
    "with open(best_run_dir / \"logs.json\", \"r\") as file:\n",
    "    logs = json.load(file)\n",
    "\n",
    "ax_left.plot(logs[\"train_loss\"], label=\"Training loss\")\n",
    "ax_left.plot(logs[\"valid_loss\"], label=\"Validation loss\")\n",
    "ax_right.plot(logs[\"train_accuracy\"], label=\"Training accuracy\")\n",
    "ax_right.plot(logs[\"valid_accuracy\"], label=\"Validation accuracy\")\n",
    "\n",
    "ax_left.legend()\n",
    "ax_right.legend()\n",
    "\n",
    "fig.savefig(\"plots/exercise-1-unoptimized.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_checkpoint(run_dir=best_run_dir, test_dataloader=test_dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = pathlib.Path(\"runs_hyperopt_random\")\n",
    "\n",
    "optimize_hyperparameters(\n",
    "    dataset=train_dataset,\n",
    "    space=space,\n",
    "    algo=rand.suggest,\n",
    "    max_evals=50,\n",
    "    n_splits=5,\n",
    "    batch_size=8,\n",
    "    random_state=42,\n",
    "    max_epochs=30,\n",
    "    patience=3,\n",
    "    device=device,\n",
    "    log_folder=log_folder,\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "find_best_hyperparameters(log_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = pathlib.Path(\"runs_hyperopt_tpe\")\n",
    "\n",
    "optimize_hyperparameters(\n",
    "    dataset=train_dataset,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    n_splits=5,\n",
    "    batch_size=8,\n",
    "    random_state=42,\n",
    "    max_epochs=30,\n",
    "    patience=3,\n",
    "    device=device,\n",
    "    log_folder=log_folder,\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "find_best_hyperparameters(log_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = pathlib.Path(\"runs_manual\")\n",
    "trial_id = \"trial_after_hyperopt\"\n",
    "\n",
    "average_valid_loss = kfold_train(\n",
    "    dataset=train_dataset,\n",
    "    n_splits=5,\n",
    "    batch_size=8,\n",
    "    random_state=42,\n",
    "    num_conv_blocks=2,\n",
    "    num_base_channels=4,\n",
    "    kernel_size_conv=3,\n",
    "    kernel_size_pool=3,\n",
    "    activation=\"relu\",\n",
    "    optimizer=\"adam\",\n",
    "    learning_rate=0.001,\n",
    "    max_epochs=30,\n",
    "    patience=3,\n",
    "    device=device,\n",
    "    log_folder=log_folder,\n",
    "    trial_id=trial_id,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_left, ax_right) = plt.subplots(1, 2, dpi=250, figsize=(14, 6))\n",
    "ax_left.set_xlabel(\"Epoch\")\n",
    "ax_right.set_xlabel(\"Epoch\")\n",
    "ax_left.set_title(\"Training/validation loss\")\n",
    "ax_right.set_title(\"Training/validation accuracy\")\n",
    "\n",
    "best_run_dir = find_best_run(log_folder / trial_id)\n",
    "\n",
    "with open(best_run_dir / \"logs.json\", \"r\") as file:\n",
    "    logs = json.load(file)\n",
    "\n",
    "ax_left.plot(logs[\"train_loss\"], label=\"Training loss\")\n",
    "ax_left.plot(logs[\"valid_loss\"], label=\"Validation loss\")\n",
    "ax_right.plot(logs[\"train_accuracy\"], label=\"Training accuracy\")\n",
    "ax_right.plot(logs[\"valid_accuracy\"], label=\"Validation accuracy\")\n",
    "\n",
    "ax_left.legend()\n",
    "ax_right.legend()\n",
    "\n",
    "fig.savefig(\"plots/exercise-3-optimized.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_checkpoint(run_dir=best_run_dir, test_dataloader=test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-defect-detection",
   "language": "python",
   "name": "deep-defect-detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
